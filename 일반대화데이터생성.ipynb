{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a144b8e6-745c-4266-a1b7-4e1b978eacad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 00_협박대응 시나리오 생성 시작 (목표: 250개) ---\n",
      "00_협박대응: 10/250 완료...\n",
      "00_협박대응: 20/250 완료...\n",
      "00_협박대응: 30/250 완료...\n",
      "00_협박대응: 40/250 완료...\n",
      "00_협박대응: 50/250 완료...\n",
      "00_협박대응: 60/250 완료...\n",
      "00_협박대응: 70/250 완료...\n",
      "00_협박대응: 80/250 완료...\n",
      "00_협박대응: 90/250 완료...\n",
      "00_협박대응: 100/250 완료...\n",
      "00_협박대응: 110/250 완료...\n",
      "00_협박대응: 120/250 완료...\n",
      "00_협박대응: 130/250 완료...\n",
      "00_협박대응: 140/250 완료...\n",
      "00_협박대응: 150/250 완료...\n",
      "00_협박대응: 160/250 완료...\n",
      "00_협박대응: 170/250 완료...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 109\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# --- 실행부 ---\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m# 1. 일반 대화 데이터 1,000개 생성 (시간이 다소 소요될 수 있습니다)\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     normal_conversations_df \u001b[38;5;241m=\u001b[39m generate_hard_negatives()\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# 2. 기존 train.csv와 병합 및 저장\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     merge_and_save(normal_conversations_df)\n",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m, in \u001b[0;36mgenerate_hard_negatives\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124m당신은 한국어 괴롭힘 분류 모델의 성능 향상을 위한 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m하드 네거티브\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 일반 대화 생성기입니다.\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124m목표: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m과 어휘적으로 유사하지만, 실제로는 무해한 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m일반 대화(04)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m를 생성하세요.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124m형식: 5턴 이상의 대화문만 출력하세요. (예: 인물A: 내용 / 인물B: 내용)\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     62\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     63\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     64\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_prompt},\n\u001b[0;32m     65\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m새로운 하드 네거티브 일반 대화 샘플을 하나 생성해줘.\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     66\u001b[0m         ],\n\u001b[0;32m     67\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;66;03m# 다양성을 위한 설정 \u001b[39;00m\n\u001b[0;32m     68\u001b[0m     )\n\u001b[0;32m     70\u001b[0m     conv_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     71\u001b[0m     generated_data\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m일반 대화\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversation\u001b[39m\u001b[38;5;124m\"\u001b[39m: conv_text})\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    916\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    917\u001b[0m             {\n\u001b[0;32m    918\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    919\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    920\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m    921\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    922\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    923\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    924\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    925\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    926\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    927\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    928\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    929\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m    930\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    931\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    932\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m    933\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    934\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m    935\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    936\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    937\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    938\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    939\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    940\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    941\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    942\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    943\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    944\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    945\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    946\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    947\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    948\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m    949\u001b[0m             },\n\u001b[0;32m    950\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    951\u001b[0m         ),\n\u001b[0;32m    952\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    953\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    954\u001b[0m         ),\n\u001b[0;32m    955\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    956\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    957\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    958\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\openai\\_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    920\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    921\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    922\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    923\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    924\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m    925\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    956\u001b[0m         request,\n\u001b[0;32m    957\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    959\u001b[0m     )\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    961\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[0;32m    910\u001b[0m )\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    915\u001b[0m     request,\n\u001b[0;32m    916\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    917\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    918\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    919\u001b[0m )\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    943\u001b[0m         request,\n\u001b[0;32m    944\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    945\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    946\u001b[0m     )\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpx\\_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1012\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    231\u001b[0m )\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    242\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool_lock:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;66;03m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;66;03m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpcore\\_sync\\http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpcore\\_sync\\http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    105\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    106\u001b[0m     (\n\u001b[0;32m    107\u001b[0m         http_version,\n\u001b[0;32m    108\u001b[0m         status,\n\u001b[0;32m    109\u001b[0m         reason_phrase,\n\u001b[0;32m    110\u001b[0m         headers,\n\u001b[1;32m--> 111\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    112\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    113\u001b[0m         http_version,\n\u001b[0;32m    114\u001b[0m         status,\n\u001b[0;32m    115\u001b[0m         reason_phrase,\n\u001b[0;32m    116\u001b[0m         headers,\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    120\u001b[0m     status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[0;32m    121\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     },\n\u001b[0;32m    128\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpcore\\_sync\\http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    173\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpcore\\_sync\\http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 212\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    214\u001b[0m     )\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\ssl.py:1285\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1284\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\new_env2\\Lib\\ssl.py:1140\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "# [초기 설정] API 키와 클라이언트 설정\n",
    "# 여기에 본인의 OpenAI API Key를 입력하세요.\n",
    "API_KEY = \"api key\"\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "def generate_hard_negatives():\n",
    "    \"\"\"\n",
    "    연구 논문의 방법론에 따라 4가지 괴롭힘 클래스에 대응하는 \n",
    "    하드 네거티브 일반 대화(Class 04) 1,000개를 생성합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1단계: 도메인 분석 및 시나리오 설계 [cite: 70]\n",
    "    # 각 괴롭힘 유형(00~03)에 대응하는 하드 네거티브 시나리오 정의\n",
    "    scenarios = {\n",
    "        \"00_협박대응\": {\n",
    "            \"target\": \"협박(00)\",\n",
    "            \"desc\": \"층간소음, 주차 문제 등에 대해 법적 절차와 경찰 신고를 언급하는 정당하고 단호한 경고 [cite: 47]\",\n",
    "            \"count\": 250\n",
    "        },\n",
    "        \"01_갈취대응\": {\n",
    "            \"target\": \"갈취(01)\",\n",
    "            \"desc\": \"친구 사이의 소액 빌리기, 중고 거래 흥정, 생일 선물 제안 등 상호 호혜적 금전 대화 [cite: 50]\",\n",
    "            \"count\": 250\n",
    "        },\n",
    "        \"02_직장대응\": {\n",
    "            \"target\": \"직장 내 괴롭힘(02)\",\n",
    "            \"desc\": \"인격 모독 없이 전문적인 비즈니스 가이드라인에 따른 엄격한 업무 피드백 및 수정 지시 [cite: 52]\",\n",
    "            \"count\": 250\n",
    "        },\n",
    "        \"03_기타대응\": {\n",
    "            \"target\": \"기타 괴롭힘(03)\",\n",
    "            \"desc\": \"외모나 신체를 언급하되 발화자 간의 정서적 지지와 공통된 웃음이 포함된 친밀한 장난 [cite: 54]\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    generated_data = []\n",
    "\n",
    "    for key, info in scenarios.items():\n",
    "        print(f\"--- {key} 시나리오 생성 시작 (목표: {info['count']}개) ---\")\n",
    "        \n",
    "        for i in range(info['count']):\n",
    "            # 2, 3단계: 의도 사슬(CoI) 및 스타일 대조 학습(SCL) 프롬프트 적용 [cite: 21, 38]\n",
    "            system_prompt = f\"\"\"\n",
    "            당신은 한국어 괴롭힘 분류 모델의 성능 향상을 위한 '하드 네거티브' 일반 대화 생성기입니다.\n",
    "            목표: {info['target']}과 어휘적으로 유사하지만, 실제로는 무해한 '일반 대화(04)'를 생성하세요.\n",
    "            \n",
    "            [지침]\n",
    "            1. 의도 사슬(CoI): 대화는 [상황 발생 -> 의견 교환 -> 상세 설명 -> 합리적 수용]의 흐름을 가져야 합니다. [cite: 28]\n",
    "            2. 스타일(SCL): 실제 한국어 구어체(감탄사, '~하네요', '~했나 봐요')를 사용하여 현실성을 높이세요. \n",
    "            3. 맥락: {info['desc']}\n",
    "            4. 제약: 인격 모독이나 위법적 행위는 절대 포함하지 마세요.\n",
    "            \n",
    "            형식: 5턴 이상의 대화문만 출력하세요. (예: 인물A: 내용 / 인물B: 내용)\n",
    "            \"\"\"\n",
    "            \n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": \"새로운 하드 네거티브 일반 대화 샘플을 하나 생성해줘.\"}\n",
    "                    ],\n",
    "                    temperature=0.8 # 다양성을 위한 설정 \n",
    "                )\n",
    "                \n",
    "                conv_text = response.choices[0].message.content.strip()\n",
    "                generated_data.append({\"class\": \"일반 대화\", \"conversation\": conv_text})\n",
    "                \n",
    "                # API 호출 간격 조절 (Rate Limit 방지)\n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f\"{key}: {i+1}/{info['count']} 완료...\")\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"오류 발생: {e}\")\n",
    "                continue\n",
    "\n",
    "    return pd.DataFrame(generated_data)\n",
    "\n",
    "# 4단계: 데이터 통합 및 모델 재학습 준비 \n",
    "def merge_and_save(new_df, original_path='train.csv'):\n",
    "    try:\n",
    "        # 1. 기존 데이터 로드 (00~03 클래스)\n",
    "        original_train = pd.read_csv(original_path)\n",
    "        \n",
    "        # 2. 데이터 병합\n",
    "        # 기존 데이터와 생성된 1,000개의 일반 대화 데이터를 합칩니다.\n",
    "        total_train = pd.concat([original_train, new_df], ignore_index=True)\n",
    "        \n",
    "        # 3. 데이터 셔플 (순서 섞기)\n",
    "        # 특정 클래스가 몰려 있지 않도록 무작위로 섞습니다.\n",
    "        total_train = total_train.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        # 4. 최종 결과 저장\n",
    "        save_name = 'total_train_with_normal.csv'\n",
    "        total_train.to_csv(save_name, index=False, encoding='utf-8-sig')\n",
    "        print(f\"성공: {len(total_train)}개의 데이터가 {save_name}에 저장되었습니다.\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"오류: train.csv 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n",
    "\n",
    "# --- 실행부 ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 일반 대화 데이터 1,000개 생성 (시간이 다소 소요될 수 있습니다)\n",
    "    normal_conversations_df = generate_hard_negatives()\n",
    "    \n",
    "    # 2. 기존 train.csv와 병합 및 저장\n",
    "    merge_and_save(normal_conversations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae8cfd-036b-4972-a2d1-67ceb28203a7",
   "metadata": {},
   "source": [
    "# Feature 2. Hard negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9dc7c48-6107-4dbc-9cbc-738f341be4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 00_협박대응 시나리오 생성 시작 (목표: 250개) ---\n",
      "00_협박대응: 10/250 완료... (현재 총 10개)\n",
      "00_협박대응: 20/250 완료... (현재 총 20개)\n",
      "00_협박대응: 30/250 완료... (현재 총 30개)\n",
      "00_협박대응: 40/250 완료... (현재 총 40개)\n",
      "00_협박대응: 50/250 완료... (현재 총 50개)\n",
      "00_협박대응: 60/250 완료... (현재 총 60개)\n",
      "00_협박대응: 70/250 완료... (현재 총 70개)\n",
      "00_협박대응: 80/250 완료... (현재 총 80개)\n",
      "00_협박대응: 90/250 완료... (현재 총 90개)\n",
      "00_협박대응: 100/250 완료... (현재 총 100개)\n",
      "00_협박대응: 110/250 완료... (현재 총 110개)\n",
      "00_협박대응: 120/250 완료... (현재 총 120개)\n",
      "00_협박대응: 130/250 완료... (현재 총 130개)\n",
      "00_협박대응: 140/250 완료... (현재 총 140개)\n",
      "00_협박대응: 150/250 완료... (현재 총 150개)\n",
      "00_협박대응: 160/250 완료... (현재 총 160개)\n",
      "00_협박대응: 170/250 완료... (현재 총 170개)\n",
      "00_협박대응: 180/250 완료... (현재 총 180개)\n",
      "00_협박대응: 190/250 완료... (현재 총 190개)\n",
      "00_협박대응: 200/250 완료... (현재 총 200개)\n",
      "00_협박대응: 210/250 완료... (현재 총 210개)\n",
      "00_협박대응: 220/250 완료... (현재 총 220개)\n",
      "00_협박대응: 230/250 완료... (현재 총 230개)\n",
      "00_협박대응: 240/250 완료... (현재 총 240개)\n",
      "00_협박대응: 250/250 완료... (현재 총 250개)\n",
      "--- 01_갈취대응 시나리오 생성 시작 (목표: 250개) ---\n",
      "01_갈취대응: 10/250 완료... (현재 총 260개)\n",
      "01_갈취대응: 20/250 완료... (현재 총 270개)\n",
      "01_갈취대응: 30/250 완료... (현재 총 280개)\n",
      "01_갈취대응: 40/250 완료... (현재 총 290개)\n",
      "01_갈취대응: 50/250 완료... (현재 총 300개)\n",
      "01_갈취대응: 60/250 완료... (현재 총 310개)\n",
      "01_갈취대응: 70/250 완료... (현재 총 320개)\n",
      "01_갈취대응: 80/250 완료... (현재 총 330개)\n",
      "01_갈취대응: 90/250 완료... (현재 총 340개)\n",
      "01_갈취대응: 100/250 완료... (현재 총 350개)\n",
      "01_갈취대응: 110/250 완료... (현재 총 360개)\n",
      "01_갈취대응: 120/250 완료... (현재 총 370개)\n",
      "01_갈취대응: 130/250 완료... (현재 총 380개)\n",
      "01_갈취대응: 140/250 완료... (현재 총 390개)\n",
      "01_갈취대응: 150/250 완료... (현재 총 400개)\n",
      "01_갈취대응: 160/250 완료... (현재 총 410개)\n",
      "01_갈취대응: 170/250 완료... (현재 총 420개)\n",
      "01_갈취대응: 180/250 완료... (현재 총 430개)\n",
      "01_갈취대응: 190/250 완료... (현재 총 440개)\n",
      "01_갈취대응: 200/250 완료... (현재 총 450개)\n",
      "01_갈취대응: 210/250 완료... (현재 총 460개)\n",
      "01_갈취대응: 220/250 완료... (현재 총 470개)\n",
      "01_갈취대응: 230/250 완료... (현재 총 480개)\n",
      "01_갈취대응: 240/250 완료... (현재 총 490개)\n",
      "01_갈취대응: 250/250 완료... (현재 총 500개)\n",
      "--- 02_직장대응 시나리오 생성 시작 (목표: 250개) ---\n",
      "02_직장대응: 10/250 완료... (현재 총 510개)\n",
      "02_직장대응: 20/250 완료... (현재 총 520개)\n",
      "02_직장대응: 30/250 완료... (현재 총 530개)\n",
      "02_직장대응: 40/250 완료... (현재 총 540개)\n",
      "02_직장대응: 50/250 완료... (현재 총 550개)\n",
      "02_직장대응: 60/250 완료... (현재 총 560개)\n",
      "02_직장대응: 70/250 완료... (현재 총 570개)\n",
      "02_직장대응: 80/250 완료... (현재 총 580개)\n",
      "02_직장대응: 90/250 완료... (현재 총 590개)\n",
      "02_직장대응: 100/250 완료... (현재 총 600개)\n",
      "02_직장대응: 110/250 완료... (현재 총 610개)\n",
      "02_직장대응: 120/250 완료... (현재 총 620개)\n",
      "02_직장대응: 130/250 완료... (현재 총 630개)\n",
      "02_직장대응: 140/250 완료... (현재 총 640개)\n",
      "02_직장대응: 150/250 완료... (현재 총 650개)\n",
      "02_직장대응: 160/250 완료... (현재 총 660개)\n",
      "02_직장대응: 170/250 완료... (현재 총 670개)\n",
      "02_직장대응: 180/250 완료... (현재 총 680개)\n",
      "02_직장대응: 190/250 완료... (현재 총 690개)\n",
      "02_직장대응: 200/250 완료... (현재 총 700개)\n",
      "02_직장대응: 210/250 완료... (현재 총 710개)\n",
      "02_직장대응: 220/250 완료... (현재 총 720개)\n",
      "02_직장대응: 230/250 완료... (현재 총 730개)\n",
      "02_직장대응: 240/250 완료... (현재 총 740개)\n",
      "02_직장대응: 250/250 완료... (현재 총 750개)\n",
      "--- 03_기타대응 시나리오 생성 시작 (목표: 250개) ---\n",
      "03_기타대응: 10/250 완료... (현재 총 760개)\n",
      "03_기타대응: 20/250 완료... (현재 총 770개)\n",
      "03_기타대응: 30/250 완료... (현재 총 780개)\n",
      "03_기타대응: 40/250 완료... (현재 총 790개)\n",
      "03_기타대응: 50/250 완료... (현재 총 800개)\n",
      "03_기타대응: 60/250 완료... (현재 총 810개)\n",
      "03_기타대응: 70/250 완료... (현재 총 820개)\n",
      "03_기타대응: 80/250 완료... (현재 총 830개)\n",
      "03_기타대응: 90/250 완료... (현재 총 840개)\n",
      "03_기타대응: 100/250 완료... (현재 총 850개)\n",
      "03_기타대응: 110/250 완료... (현재 총 860개)\n",
      "03_기타대응: 120/250 완료... (현재 총 870개)\n",
      "03_기타대응: 130/250 완료... (현재 총 880개)\n",
      "03_기타대응: 140/250 완료... (현재 총 890개)\n",
      "03_기타대응: 150/250 완료... (현재 총 900개)\n",
      "03_기타대응: 160/250 완료... (현재 총 910개)\n",
      "03_기타대응: 170/250 완료... (현재 총 920개)\n",
      "03_기타대응: 180/250 완료... (현재 총 930개)\n",
      "03_기타대응: 190/250 완료... (현재 총 940개)\n",
      "03_기타대응: 200/250 완료... (현재 총 950개)\n",
      "03_기타대응: 210/250 완료... (현재 총 960개)\n",
      "03_기타대응: 220/250 완료... (현재 총 970개)\n",
      "03_기타대응: 230/250 완료... (현재 총 980개)\n",
      "03_기타대응: 240/250 완료... (현재 총 990개)\n",
      "03_기타대응: 250/250 완료... (현재 총 1000개)\n",
      "✅ 최종 성공: 총 4950개의 데이터(새 데이터 1000개 포함)가 total_train_with_normal.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "# [초기 설정] API 키와 클라이언트 설정\n",
    "API_KEY = \"api key\"\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "def generate_hard_negatives():\n",
    "    \"\"\"\n",
    "    연구 논문의 방법론에 따라 하드 네거티브 일반 대화(Class 04)를 생성합니다.\n",
    "    중간에 정지해도 그때까지 생성된 데이터를 반환합니다. [cite: 9, 70]\n",
    "    \"\"\"\n",
    "    \n",
    "    scenarios = {\n",
    "        \"00_협박대응\": {\n",
    "            \"target\": \"협박(00)\",\n",
    "            \"desc\": \"층간소음, 주차 문제 등에 대해 법적 절차와 경찰 신고를 언급하는 정당하고 단호한 경고 [cite: 47]\",\n",
    "            \"count\": 250\n",
    "        },\n",
    "        \"01_갈취대응\": {\n",
    "            \"target\": \"갈취(01)\",\n",
    "            \"desc\": \"친구 사이의 소액 빌리기, 중고 거래 흥정, 생일 선물 제안 등 상호 호혜적 금전 대화 [cite: 50]\",\n",
    "            \"count\": 250\n",
    "        },\n",
    "        \"02_직장대응\": {\n",
    "            \"target\": \"직장 내 괴롭힘(02)\",\n",
    "            \"desc\": \"인격 모독 없이 전문적인 비즈니스 가이드라인에 따른 엄격한 업무 피드백 및 수정 지시 [cite: 52]\",\n",
    "            \"count\": 250\n",
    "        },\n",
    "        \"03_기타대응\": {\n",
    "            \"target\": \"기타 괴롭힘(03)\",\n",
    "            \"desc\": \"외모나 신체를 언급하되 발화자 간의 정서적 지지와 공통된 웃음이 포함된 친밀한 장난 [cite: 54]\",\n",
    "            \"count\": 250\n",
    "        }\n",
    "    }\n",
    "\n",
    "    generated_data = []\n",
    "\n",
    "    try:\n",
    "        for key, info in scenarios.items():\n",
    "            print(f\"--- {key} 시나리오 생성 시작 (목표: {info['count']}개) ---\")\n",
    "            \n",
    "            for i in range(info['count']):\n",
    "                # 모델을 gpt-4o-mini로 변경하여 비용 절감 \n",
    "                system_prompt = f\"\"\"\n",
    "                당신은 한국어 괴롭힘 분류 모델의 성능 향상을 위한 '하드 네거티브' 일반 대화 생성기입니다.\n",
    "                목표: {info['target']}과 어휘적으로 유사하지만, 실제로는 무해한 '일반 대화(04)'를 생성하세요. [cite: 14]\n",
    "                \n",
    "                [지침]\n",
    "                1. 의도 사슬(CoI): [상황 발생 -> 의견 교환 -> 상세 설명 -> 합리적 수용] 흐름 준수 [cite: 28]\n",
    "                2. 스타일(SCL): 실제 한국어 구어체(감탄사, '~하네요', '~했나 봐요') 활용 [cite: 40]\n",
    "                3. 맥락: {info['desc']}\n",
    "                4. 제약: 인격 모독이나 위법적 행위 절대 금지 [cite: 52]\n",
    "                \n",
    "                형식: 5턴 이상의 대화문만 출력 (예: 인물A: 내용 / 인물B: 내용)\n",
    "                \"\"\"\n",
    "                \n",
    "                try:\n",
    "                    response = client.chat.completions.create(\n",
    "                        model=\"gpt-4o-mini\", # 비용 효율적인 모델로 변경\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": system_prompt},\n",
    "                            {\"role\": \"user\", \"content\": \"새로운 하드 네거티브 일반 대화 샘플을 하나 생성해줘.\"}\n",
    "                        ],\n",
    "                        temperature=0.8\n",
    "                    )\n",
    "                    \n",
    "                    conv_text = response.choices[0].message.content.strip()\n",
    "                    generated_data.append({\"class\": \"일반 대화\", \"conversation\": conv_text})\n",
    "                    \n",
    "                    if (i + 1) % 10 == 0:\n",
    "                        print(f\"{key}: {i+1}/{info['count']} 완료... (현재 총 {len(generated_data)}개)\")\n",
    "                        time.sleep(0.5)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"API 오류 발생: {e}\")\n",
    "                    continue\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # 주피터 노트북에서 '정지' 버튼을 누르면 이 구간이 실행됩니다.\n",
    "        print(\"\\n🛑 사용자에 의해 생성이 중단되었습니다. 현재까지 생성된 데이터를 저장합니다...\")\n",
    "\n",
    "    # 중단되더라도 생성된 만큼은 데이터프레임으로 변환하여 반환\n",
    "    return pd.DataFrame(generated_data)\n",
    "\n",
    "def merge_and_save(new_df, original_path='train.csv'):\n",
    "    if new_df.empty:\n",
    "        print(\"생성된 데이터가 없어 병합을 중단합니다.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        original_train = pd.read_csv(original_path)\n",
    "        total_train = pd.concat([original_train, new_df], ignore_index=True)\n",
    "        total_train = total_train.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        save_name = 'total_train_with_normal.csv'\n",
    "        total_train.to_csv(save_name, index=False, encoding='utf-8-sig')\n",
    "        print(f\"✅ 최종 성공: 총 {len(total_train)}개의 데이터(새 데이터 {len(new_df)}개 포함)가 {save_name}에 저장되었습니다.\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        # train.csv가 없을 경우 생성된 데이터라도 따로 저장\n",
    "        new_df.to_csv('generated_normal_only.csv', index=False, encoding='utf-8-sig')\n",
    "        print(f\"⚠️ train.csv를 찾을 수 없어 생성된 {len(new_df)}개의 데이터만 별도로 저장했습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    normal_conversations_df = generate_hard_negatives()\n",
    "    merge_and_save(normal_conversations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e71bf1-ab1d-4c61-9bf8-6a3b16b4bdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 정제된 일반 대화 예시 ---\n",
      "요즘 너 살 좀 빠진 것 같아, 운동 열심히 했나?\n",
      "아, 진짜? 그런 거 같기도 해! 그냥 매일 걸어다니려고 노력하고 있어.\n",
      "그러게, 요즘 좋은 생각이네. 나도 좀 따라 해야겠다. 나 저번에 체중계 올라갔는데 깜짝 놀랐어!\n",
      "뭐야, 얼마야? 너무 궁금하잖아!\n",
      "비밀이야! 그냥 살짝만 늘었지 뭐. 너처럼 운동 열심히 해야겠다, 진짜!\n",
      "하하, 괜찮아. 우리 같이 운동하자! 그러면 서로 동기 부여도 되고 재밌을 것 같아.\n",
      "좋지! 그러면서 서로의 운동복 패션도 비교해보자!\n",
      "\n",
      "✅ 모든 클래스의 형식이 일치된 'total_train_final.csv' 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_speaker_labels(text):\n",
    "    \"\"\"\n",
    "    문장 시작 부분의 '화자명: ' 패턴을 제거합니다.\n",
    "    예: '인물A: 안녕하세요' -> '안녕하세요'\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    # 정규표현식 설명:\n",
    "    # ^: 줄의 시작\n",
    "    # [^:\\n]+: 콜론(:)이나 줄바꿈이 아닌 문자들이 하나 이상 나옴 (화자 이름)\n",
    "    # :\\s*: 콜론과 그 뒤의 공백문자\n",
    "    cleaned_text = re.sub(r'^[^:\\n]+:\\s*', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # 각 줄의 앞뒤 불필요한 공백 제거\n",
    "    lines = [line.strip() for line in cleaned_text.split('\\n')]\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "# 1. 데이터 로드\n",
    "df = pd.read_csv('total_train_with_normal.csv')\n",
    "\n",
    "# 2. '일반 대화' 클래스에만 정제 함수 적용\n",
    "# 기존 클래스(00~03)는 건드리지 않고 새로 만든 데이터만 수정합니다.\n",
    "df.loc[df['class'] == '일반 대화', 'conversation'] = df.loc[df['class'] == '일반 대화', 'conversation'].apply(clean_speaker_labels)\n",
    "\n",
    "# 3. 결과 확인 (샘플 출력)\n",
    "print(\"--- 정제된 일반 대화 예시 ---\")\n",
    "print(df[df['class'] == '일반 대화']['conversation'].iloc[0])\n",
    "\n",
    "# 4. 최종 통합 데이터 저장\n",
    "df.to_csv('total_train_final.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\n✅ 모든 클래스의 형식이 일치된 'total_train_final.csv' 파일이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "133bea7b-7b69-4297-8c9f-5cf167f64d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (1.70.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (2.2.3)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from openai) (4.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from openai) (2.11.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn)\n",
      "  Downloading scipy-1.17.0-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jh\\anaconda3\\envs\\new_env2\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading scikit_learn-1.8.0-cp313-cp313-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/8.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.0/8.0 MB 2.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/8.0 MB 2.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.3/8.0 MB 1.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.6/8.0 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.6/8.0 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.2/8.0 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 6.6/8.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 4.4 MB/s  0:00:01\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading scipy-1.17.0-cp313-cp313-win_amd64.whl (36.3 MB)\n",
      "   ---------------------------------------- 0.0/36.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.8/36.3 MB 10.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 2.4/36.3 MB 5.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.6/36.3 MB 3.8 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 2.9/36.3 MB 3.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 3.9/36.3 MB 3.5 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 5.8/36.3 MB 4.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 6.6/36.3 MB 4.5 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 6.8/36.3 MB 4.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 7.1/36.3 MB 3.6 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.1/36.3 MB 3.7 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 8.4/36.3 MB 3.8 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 8.7/36.3 MB 3.6 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 8.9/36.3 MB 3.2 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 9.4/36.3 MB 3.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 9.7/36.3 MB 3.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 10.0/36.3 MB 2.9 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 10.0/36.3 MB 2.9 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 10.5/36.3 MB 2.7 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 12.1/36.3 MB 3.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 14.2/36.3 MB 3.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 16.5/36.3 MB 3.7 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 19.1/36.3 MB 4.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 21.5/36.3 MB 4.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 24.1/36.3 MB 4.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 26.5/36.3 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 29.1/36.3 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 31.5/36.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 34.1/36.3 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  36.2/36.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 36.3/36.3 MB 5.8 MB/s  0:00:06\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.3 scikit-learn-1.8.0 scipy-1.17.0 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918ae356-4d45-491c-8485-29ddb38b904c",
   "metadata": {},
   "source": [
    "# Feature 3.Augmentation을 통한 데이터 증강 및 LLM 판사도입을 통한 일반 대화 데이터 편집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df56315-4f2d-46e6-a0f5-427947c0b16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 train.csv 로드 완료 (3950개)\n",
      "\n",
      "🚀 기존 데이터 증강 시작 (각 클래스별 1000개 생성 목표)...\n",
      "--- Class '협박 대화' 증강 중 ---\n",
      "   50/1000 완료...\n",
      "   100/1000 완료...\n",
      "   150/1000 완료...\n",
      "   200/1000 완료...\n",
      "   250/1000 완료...\n",
      "   300/1000 완료...\n",
      "   350/1000 완료...\n",
      "   400/1000 완료...\n",
      "   450/1000 완료...\n",
      "   500/1000 완료...\n",
      "   550/1000 완료...\n",
      "   600/1000 완료...\n",
      "   650/1000 완료...\n",
      "   700/1000 완료...\n",
      "   750/1000 완료...\n",
      "   800/1000 완료...\n",
      "   850/1000 완료...\n",
      "   900/1000 완료...\n",
      "   950/1000 완료...\n",
      "   1000/1000 완료...\n",
      "--- Class '기타 괴롭힘 대화' 증강 중 ---\n",
      "   50/1000 완료...\n",
      "   100/1000 완료...\n",
      "   150/1000 완료...\n",
      "   200/1000 완료...\n",
      "   250/1000 완료...\n",
      "   300/1000 완료...\n",
      "   350/1000 완료...\n",
      "   400/1000 완료...\n",
      "   450/1000 완료...\n",
      "   500/1000 완료...\n",
      "   550/1000 완료...\n",
      "   600/1000 완료...\n",
      "   650/1000 완료...\n",
      "   700/1000 완료...\n",
      "   750/1000 완료...\n",
      "   800/1000 완료...\n",
      "   850/1000 완료...\n",
      "   900/1000 완료...\n",
      "   950/1000 완료...\n",
      "   1000/1000 완료...\n",
      "--- Class '갈취 대화' 증강 중 ---\n",
      "   50/1000 완료...\n",
      "   100/1000 완료...\n",
      "   150/1000 완료...\n",
      "   200/1000 완료...\n",
      "   250/1000 완료...\n",
      "   300/1000 완료...\n",
      "   350/1000 완료...\n",
      "   400/1000 완료...\n",
      "   450/1000 완료...\n",
      "   500/1000 완료...\n",
      "   550/1000 완료...\n",
      "   600/1000 완료...\n",
      "   650/1000 완료...\n",
      "   700/1000 완료...\n",
      "   750/1000 완료...\n",
      "   800/1000 완료...\n",
      "   850/1000 완료...\n",
      "   900/1000 완료...\n",
      "   950/1000 완료...\n",
      "   1000/1000 완료...\n",
      "--- Class '직장 내 괴롭힘 대화' 증강 중 ---\n",
      "   50/1000 완료...\n",
      "   100/1000 완료...\n",
      "   150/1000 완료...\n",
      "   200/1000 완료...\n",
      "   250/1000 완료...\n",
      "   300/1000 완료...\n",
      "   350/1000 완료...\n",
      "   400/1000 완료...\n",
      "   450/1000 완료...\n",
      "   500/1000 완료...\n",
      "   550/1000 완료...\n",
      "   600/1000 완료...\n",
      "   650/1000 완료...\n",
      "   700/1000 완료...\n",
      "   750/1000 완료...\n",
      "   800/1000 완료...\n",
      "   850/1000 완료...\n",
      "   900/1000 완료...\n",
      "   950/1000 완료...\n",
      "   1000/1000 완료...\n",
      "\n",
      "📊 유사도 분석을 위한 데이터 벡터화 중...\n",
      "\n",
      "--- 00_협박대응 시나리오 생성 시작 (목표: 500개) ---\n",
      "   ✅ 00_협박대응: 50/500 생성 완료\n",
      "   ✅ 00_협박대응: 100/500 생성 완료\n",
      "   ✅ 00_협박대응: 150/500 생성 완료\n",
      "   ✅ 00_협박대응: 200/500 생성 완료\n",
      "   ✅ 00_협박대응: 250/500 생성 완료\n",
      "   ✅ 00_협박대응: 300/500 생성 완료\n",
      "   ✅ 00_협박대응: 350/500 생성 완료\n",
      "   ✅ 00_협박대응: 400/500 생성 완료\n",
      "   ✅ 00_협박대응: 450/500 생성 완료\n",
      "   ✅ 00_협박대응: 500/500 생성 완료\n",
      "\n",
      "--- 01_갈취대응 시나리오 생성 시작 (목표: 500개) ---\n",
      "   ✅ 01_갈취대응: 50/500 생성 완료\n",
      "   ✅ 01_갈취대응: 100/500 생성 완료\n",
      "   ✅ 01_갈취대응: 150/500 생성 완료\n",
      "   ✅ 01_갈취대응: 200/500 생성 완료\n",
      "   ✅ 01_갈취대응: 250/500 생성 완료\n",
      "   ✅ 01_갈취대응: 300/500 생성 완료\n",
      "   ✅ 01_갈취대응: 350/500 생성 완료\n",
      "   ✅ 01_갈취대응: 400/500 생성 완료\n",
      "   ✅ 01_갈취대응: 450/500 생성 완료\n",
      "   ✅ 01_갈취대응: 500/500 생성 완료\n",
      "\n",
      "--- 02_직장대응 시나리오 생성 시작 (목표: 500개) ---\n",
      "   ✅ 02_직장대응: 50/500 생성 완료\n",
      "   ✅ 02_직장대응: 100/500 생성 완료\n",
      "   ✅ 02_직장대응: 150/500 생성 완료\n",
      "   ✅ 02_직장대응: 200/500 생성 완료\n",
      "   ✅ 02_직장대응: 250/500 생성 완료\n",
      "   ✅ 02_직장대응: 300/500 생성 완료\n",
      "   ✅ 02_직장대응: 350/500 생성 완료\n",
      "   ✅ 02_직장대응: 400/500 생성 완료\n",
      "   ✅ 02_직장대응: 450/500 생성 완료\n",
      "   ✅ 02_직장대응: 500/500 생성 완료\n",
      "\n",
      "--- 03_기타대응 시나리오 생성 시작 (목표: 500개) ---\n",
      "   ✅ 03_기타대응: 50/500 생성 완료\n",
      "   ✅ 03_기타대응: 100/500 생성 완료\n",
      "   ✅ 03_기타대응: 150/500 생성 완료\n",
      "   ✅ 03_기타대응: 200/500 생성 완료\n",
      "   ✅ 03_기타대응: 250/500 생성 완료\n",
      "   ✅ 03_기타대응: 300/500 생성 완료\n",
      "   ✅ 03_기타대응: 350/500 생성 완료\n",
      "   ✅ 03_기타대응: 400/500 생성 완료\n",
      "   ✅ 03_기타대응: 450/500 생성 완료\n",
      "   ✅ 03_기타대응: 500/500 생성 완료\n",
      "\n",
      "🎉 모든 작업 완료! 총 9950개의 데이터가 'final_augmented_train_2k.csv'에 저장되었습니다.\n",
      "\n",
      "📊 최종 클래스별 데이터 개수:\n",
      "class\n",
      "기타 괴롭힘 대화      2094\n",
      "일반 대화          2000\n",
      "갈취 대화          1981\n",
      "직장 내 괴롭힘 대화    1979\n",
      "협박 대화          1896\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# [초기 설정] API 키 입력\n",
    "API_KEY = \"api key\"\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 헬퍼 함수 (유사도 계산, LLM 호출)\n",
    "# ==========================================\n",
    "\n",
    "def calculate_similarity(new_text, existing_texts, vectorizer):\n",
    "    \"\"\"\n",
    "    새로운 텍스트와 기존 텍스트들 간의 코사인 유사도를 계산합니다.\n",
    "    최대 유사도가 0.95를 넘으면 True(중복)를 반환합니다.\n",
    "    \"\"\"\n",
    "    if not existing_texts:\n",
    "        return False, 0.0\n",
    "    \n",
    "    try:\n",
    "        # 벡터화 (기존 텍스트 리스트에 새 텍스트를 추가하여 변환)\n",
    "        tfidf_matrix = vectorizer.transform(existing_texts + [new_text])\n",
    "        # 마지막 행(새 텍스트)과 나머지 행들(기존) 간의 유사도 계산\n",
    "        cosine_sim = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
    "        max_sim = cosine_sim.max()\n",
    "        return max_sim > 0.95, max_sim\n",
    "    except:\n",
    "        return False, 0.0\n",
    "\n",
    "def call_llm(messages, model=\"gpt-4o-mini\", temperature=0.7):\n",
    "    \"\"\"OpenAI API 호출 래퍼 함수 (오류 처리 포함)\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"API Error: {e}\")\n",
    "        time.sleep(1) # 오류 시 잠시 대기\n",
    "        return None\n",
    "\n",
    "# ==========================================\n",
    "# 2. 핵심 기능: 데이터 증강 (Augmentation) - 1,000개 목표\n",
    "# ==========================================\n",
    "\n",
    "def augment_existing_data(df, target_count=1000):\n",
    "    \"\"\"\n",
    "    기존 train.csv의 각 클래스(00~03) 데이터를 '재작성(Paraphrasing)'하여 증강합니다.\n",
    "    목표: 클래스별 1,000개 추가 생성\n",
    "    \"\"\"\n",
    "    print(f\"\\n🚀 기존 데이터 증강 시작 (각 클래스별 {target_count}개 생성 목표)...\")\n",
    "    augmented_list = []\n",
    "    \n",
    "    # 클래스별로 데이터 분리\n",
    "    classes = df['class'].unique()\n",
    "    \n",
    "    for cls in classes:\n",
    "        if cls == '일반 대화': continue \n",
    "        \n",
    "        class_data = df[df['class'] == cls]['conversation'].tolist()\n",
    "        if not class_data: continue\n",
    "\n",
    "        print(f\"--- Class '{cls}' 증강 중 ---\")\n",
    "        \n",
    "        for i in range(target_count):\n",
    "            # 랜덤하게 원본 샘플 선택 (복원 추출)\n",
    "            original_sample = random.choice(class_data)\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "            당신은 데이터 증강 전문가입니다. 아래 대화의 '핵심 의도'와 '클래스({cls})' 특성은 유지하되, \n",
    "            문장 스타일, 단어, 상황을 조금 바꿔서 새로운 대화 데이터를 하나 만들어주세요.\n",
    "            \n",
    "            [원본 대화]\n",
    "            {original_sample}\n",
    "            \n",
    "            [요청사항]\n",
    "            1. 원본과 의미는 같지만 표현을 다르게 하세요 (예: 사투리, 줄임말, 더 격한 표현 등).\n",
    "            2. 길이는 원본과 비슷하게 유지하세요.\n",
    "            3. 결과물에는 오직 '대화 내용'만 출력하세요.\n",
    "            \"\"\"\n",
    "            \n",
    "            new_conv = call_llm([{\"role\": \"user\", \"content\": prompt}], temperature=0.9)\n",
    "            \n",
    "            if new_conv:\n",
    "                augmented_list.append({'class': cls, 'conversation': new_conv})\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f\"   {i+1}/{target_count} 완료...\")\n",
    "                \n",
    "    return pd.DataFrame(augmented_list)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 핵심 기능: 하드 네거티브 생성 - 2,000개 목표 (500 * 4)\n",
    "# ==========================================\n",
    "\n",
    "def generate_hard_negatives_advanced(existing_df):\n",
    "    \n",
    "    # 3-1. 시나리오별 500개씩 설정 (총 2,000개)\n",
    "    scenarios = {\n",
    "        \"00_협박대응\": {\n",
    "            \"target\": \"협박(00)\",\n",
    "            \"topics\": [\"층간소음 항의\", \"주차 시비\", \"중고차 사기 대응\", \"악성 댓글 고소 예고\", \"계약 불이행 내용증명\", \"기물 파손 배상 요구\", \"임금 체불 항의\", \"반려동물 소음 갈등\"],\n",
    "            \"count\": 500 \n",
    "        },\n",
    "        \"01_갈취대응\": {\n",
    "            \"target\": \"갈취(01)\",\n",
    "            \"topics\": [\"친구에게 돈 빌리기\", \"더치페이 정산 재촉\", \"중고 거래 네고(흥정)\", \"회비 걷기\", \"빌려준 물건 돌려받기\", \"생일 선물 사달라고 조르기\", \"여행 경비 정산\", \"식대 선결제 요청\"],\n",
    "            \"count\": 500\n",
    "        },\n",
    "        \"02_직장대응\": {\n",
    "            \"target\": \"직장 내 괴롭힘(02)\",\n",
    "            \"topics\": [\"마감 기한 재촉\", \"보고서 전면 수정 지시\", \"근태(지각) 지적\", \"성과 평가 면담\", \"업무 실수에 대한 경위서 요구\", \"복장 규정 안내\", \"휴가 일정 조정 요청\", \"회의 태도 지적\"],\n",
    "            \"count\": 500\n",
    "        },\n",
    "        \"03_기타대응\": {\n",
    "            \"target\": \"기타 괴롭힘(03)\",\n",
    "            \"topics\": [\"절친 간의 외모 디스(장난)\", \"패션 지적과 조언\", \"사투리/말투 흉내내기\", \"게임 실력 놀리기\", \"과거 흑역사 언급하며 웃기\", \"연애사 캐묻기(친한 사이)\", \"노래 실력 타박하기\"],\n",
    "            \"count\": 500\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 3-2. 유사도 필터링을 위한 Vectorizer 준비\n",
    "    print(\"\\n📊 유사도 분석을 위한 데이터 벡터화 중...\")\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    \n",
    "    # 기존 데이터가 있으면 fit 수행 (없으면 임시 텍스트로)\n",
    "    all_texts = existing_df['conversation'].tolist() if not existing_df.empty else [\"임시 텍스트\"]\n",
    "    vectorizer.fit(all_texts)\n",
    "    \n",
    "    generated_data = []\n",
    "    \n",
    "    try:\n",
    "        for key, info in scenarios.items():\n",
    "            print(f\"\\n--- {key} 시나리오 생성 시작 (목표: {info['count']}개) ---\")\n",
    "            success_count = 0\n",
    "            \n",
    "            while success_count < info['count']:\n",
    "                # [Diversity] 세부 토픽 랜덤 선택 (쏠림 방지)\n",
    "                topic = random.choice(info['topics'])\n",
    "                \n",
    "                # 1. 생성 (Generation)\n",
    "                gen_prompt = f\"\"\"\n",
    "                목표: '{info['target']}'과 혼동되기 쉽지만 무해한 '일반 대화(04)' 생성.\n",
    "                상황: {topic}\n",
    "                \n",
    "                [지침]\n",
    "                1. 의도 사슬(CoI): 상황 발생 -> 항의/요구 -> 설명 -> 수용\n",
    "                2. 스타일: 한국어 구어체, 감탄사 포함\n",
    "                3. 제약: 욕설, 인격 모독 절대 금지. 법적/사회적으로 정당한 범위 내의 대화.\n",
    "                \n",
    "                형식: 5턴 이상의 대화만 출력. 화자 구분(A:, B:) 포함.\n",
    "                \"\"\"\n",
    "                \n",
    "                conv_text = call_llm([{\"role\": \"system\", \"content\": gen_prompt}], temperature=0.85)\n",
    "                if not conv_text: continue\n",
    "\n",
    "                # 2. 판사 평가 (LLM-as-a-Judge)\n",
    "                judge_prompt = f\"\"\"\n",
    "                당신은 데이터 품질 판사입니다. 아래 대화가 '일반 대화'로서 적절한지 평가하세요.\n",
    "                \n",
    "                [대화]\n",
    "                {conv_text}\n",
    "                \n",
    "                [기준]\n",
    "                1. 안전성: 괴롭힘/범죄 요소가 없는가? (협박성 발언이 있어도 정당한 방어라면 통과)\n",
    "                2. 명확성: {info['target']} 클래스와 헷갈리지만 결국 '일반 대화'임이 확실한가?\n",
    "                \n",
    "                답변 형식: JSON 포맷 {{ \"score\": 1~5점, \"reason\": \"이유\" }}\n",
    "                5점이 만점, 3점 이하는 불합격.\n",
    "                \"\"\"\n",
    "                judge_res = call_llm([{\"role\": \"user\", \"content\": judge_prompt}], temperature=0.1)\n",
    "                \n",
    "                # 점수 파싱\n",
    "                score = 0\n",
    "                if judge_res:\n",
    "                    try:\n",
    "                        import re\n",
    "                        score_match = re.search(r'\"score\":\\s*(\\d)', judge_res)\n",
    "                        if score_match: score = int(score_match.group(1))\n",
    "                    except: pass\n",
    "                \n",
    "                # 3. 피드백 루프 (Feedback Loop) - 점수 낮으면 수정\n",
    "                if score < 4:\n",
    "                    # print(f\"   ↪️ [재작성] 품질 미달(점수:{score}). 수정 중...\") # 로그 너무 많으면 주석 처리\n",
    "                    rewrite_prompt = f\"\"\"\n",
    "                    판사 피드백: {judge_res}\n",
    "                    위 피드백을 반영하여 대화를 더 자연스럽고 '일반 대화'스럽게 수정해줘.\n",
    "                    \"\"\"\n",
    "                    conv_text = call_llm([\n",
    "                        {\"role\": \"user\", \"content\": gen_prompt},\n",
    "                        {\"role\": \"assistant\", \"content\": conv_text},\n",
    "                        {\"role\": \"user\", \"content\": rewrite_prompt}\n",
    "                    ])\n",
    "                \n",
    "                # 4. 유사도 필터링 (Similarity Check)\n",
    "                is_duplicate, sim_score = calculate_similarity(conv_text, all_texts, vectorizer)\n",
    "                if is_duplicate:\n",
    "                    print(f\"   🗑️ [삭제] 기존 데이터와 너무 유사함 (유사도: {sim_score:.2f})\")\n",
    "                    continue \n",
    "\n",
    "                # 통과! 저장\n",
    "                generated_data.append({\"class\": \"일반 대화\", \"conversation\": conv_text})\n",
    "                all_texts.append(conv_text) # 중복 검사용 리스트에 추가\n",
    "                \n",
    "                success_count += 1\n",
    "                if success_count % 50 == 0:\n",
    "                    print(f\"   ✅ {key}: {success_count}/{info['count']} 생성 완료\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 사용자 중단! 현재까지의 데이터를 저장합니다.\")\n",
    "    \n",
    "    return pd.DataFrame(generated_data)\n",
    "\n",
    "# ==========================================\n",
    "# 4. 메인 실행부\n",
    "# ==========================================\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # 1. 기존 데이터 로드\n",
    "        original_df = pd.read_csv('train.csv')\n",
    "        print(f\"📂 train.csv 로드 완료 ({len(original_df)}개)\")\n",
    "    except:\n",
    "        print(\"⚠️ train.csv가 없습니다. 빈 데이터프레임으로 시작합니다.\")\n",
    "        original_df = pd.DataFrame(columns=['class', 'conversation'])\n",
    "\n",
    "    # 2. 기존 데이터 증강 (Augmentation)\n",
    "    # 클래스당 1,000개 추가 생성 -> 기존 1,000개 + 증강 1,000개 = 2,000개\n",
    "    augmented_df = augment_existing_data(original_df, target_count=1000)\n",
    "    \n",
    "    # 3. 하드 네거티브 생성 (Generation)\n",
    "    # 총 2,000개 생성 (시나리오별 500개)\n",
    "    combined_for_check = pd.concat([original_df, augmented_df], ignore_index=True)\n",
    "    normal_df = generate_hard_negatives_advanced(combined_for_check)\n",
    "    \n",
    "    # 4. 최종 통합\n",
    "    final_df = pd.concat([original_df, augmented_df, normal_df], ignore_index=True)\n",
    "    \n",
    "    # 셔플 및 저장\n",
    "    final_df = final_df.sample(frac=1).reset_index(drop=True)\n",
    "    final_df.to_csv('final_augmented_train_2k.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n🎉 모든 작업 완료! 총 {len(final_df)}개의 데이터가 'final_augmented_train_2k.csv'에 저장되었습니다.\")\n",
    "    \n",
    "    # 클래스별 개수 확인 출력\n",
    "    print(\"\\n📊 최종 클래스별 데이터 개수:\")\n",
    "    print(final_df['class'].value_counts())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6494f912-a699-4c4b-9bd7-0c514bf39684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   ---------------------------------------- 2/2 [openpyxl]\n",
      "\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cba009b-5c75-4c30-adfc-1eb8c00d42dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 신규 일반 대화 300개 생성 및 엑셀 구축 시작...\n",
      "✅ 10/300개 생성 중...\n",
      "✅ 20/300개 생성 중...\n",
      "✅ 30/300개 생성 중...\n",
      "✅ 40/300개 생성 중...\n",
      "✅ 50/300개 생성 중...\n",
      "✅ 60/300개 생성 중...\n",
      "✅ 70/300개 생성 중...\n",
      "✅ 80/300개 생성 중...\n",
      "✅ 90/300개 생성 중...\n",
      "✅ 100/300개 생성 중...\n",
      "✅ 110/300개 생성 중...\n",
      "✅ 120/300개 생성 중...\n",
      "✅ 130/300개 생성 중...\n",
      "✅ 140/300개 생성 중...\n",
      "✅ 150/300개 생성 중...\n",
      "✅ 160/300개 생성 중...\n",
      "✅ 170/300개 생성 중...\n",
      "✅ 180/300개 생성 중...\n",
      "✅ 190/300개 생성 중...\n",
      "✅ 200/300개 생성 중...\n",
      "✅ 210/300개 생성 중...\n",
      "✅ 220/300개 생성 중...\n",
      "✅ 230/300개 생성 중...\n",
      "✅ 240/300개 생성 중...\n",
      "✅ 250/300개 생성 중...\n",
      "✅ 260/300개 생성 중...\n",
      "✅ 270/300개 생성 중...\n",
      "✅ 280/300개 생성 중...\n",
      "✅ 290/300개 생성 중...\n",
      "✅ 300/300개 생성 중...\n",
      "\n",
      "✨ 생성 완료! 'custom_normal_dialogue_300.xlsx' 파일이 저장되었습니다.\n",
      "   번호  class                                       conversation      설정길이  \\\n",
      "0   1  일반 대화  1. A: 야, 너 내가 만원 빌린 거 언제 갚을 거야? 진짜 죽이기 전에 내놔. ...  150~200자   \n",
      "1   2  일반 대화  2. (약 200~280자)\\n\\nA: 야, 부장님 진짜 오늘 너무 이상해. 팀 회...  200~280자   \n",
      "2   3  일반 대화  3. (약 280~350자)\\n\\nA: 진짜, 이번에도 또 밤새도록 신발 소리 왜 ...  280~350자   \n",
      "3   4  일반 대화  4. (약 200~280자)\\n\\nA: 야, 이번 게임 엉망이잖아. 왜 이렇게 못해...  200~280자   \n",
      "4   5  일반 대화  5. A: 야, 너 좀 전에 빌려준 만원 언제 줄 거야? 나 다음 주에 진짜 돈 좀...  280~350자   \n",
      "\n",
      "                     상황분류  \n",
      "0  가족 간의 사소한 오해로 시작된 큰 소리  \n",
      "1  팀장님과의 격식 없는 사적인 술자리 대화  \n",
      "2  층간소음으로 인한 이웃 간의 격한 말다툼  \n",
      "3     게임 중 팀원과의 거친 피드백 교환  \n",
      "4    친구에게 빌려준 돈을 받기 위한 재촉  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from openai import OpenAI\n",
    "\n",
    "# [초기 설정] API 키 입력\n",
    "API_KEY = \"api key\"\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "def generate_custom_normal_to_excel(total_count=300):\n",
    "    \"\"\"\n",
    "    사용자 정의 프롬프트를 기반으로 하드 네거티브 일반 대화 300개를 생성하고 엑셀로 저장합니다.\n",
    "    \"\"\"\n",
    "    generated_data = []\n",
    "    \n",
    "    # 1. 길이 조건 분산 설정 (비율 20:20:10 -> 300개 기준 120:120:60) [cite: 41]\n",
    "    # 150~200자(120개), 200~280자(120개), 280~350자(60개)\n",
    "    len_buckets = ([\"150~200자\"] * 120) + ([\"200~280자\"] * 120) + ([\"280~350자\"] * 60)\n",
    "    random.shuffle(len_buckets)\n",
    "\n",
    "    # 2. 다양성 확보를 위한 상황(Context) 예시 리스트\n",
    "    # 주제당 15개를 넘지 않도록 다양한 상황을 프롬프트에 동적으로 주입합니다. [cite: 70]\n",
    "    contexts = [\n",
    "        \"절친끼리 비속어를 섞은 거친 장난\", \"식당에서 정당한 환불 요구로 인한 실랑이\", \n",
    "        \"층간소음으로 인한 이웃 간의 격한 말다툼\", \"연인 간의 이별 통보와 감정적 다툼\",\n",
    "        \"중고 거래 중 돈 문제로 인한 경찰 언급 시나리오\", \"친구에게 빌려준 돈을 받기 위한 재촉\",\n",
    "        \"팀장님과의 격식 없는 사적인 술자리 대화\", \"가족 간의 사소한 오해로 시작된 큰 소리\",\n",
    "        \"게임 중 팀원과의 거친 피드백 교환\", \"주차 문제로 인한 차주들 간의 실랑이\"\n",
    "    ]\n",
    "\n",
    "    print(f\"🚀 신규 일반 대화 {total_count}개 생성 및 엑셀 구축 시작...\")\n",
    "\n",
    "    try:\n",
    "        for i in range(total_count):\n",
    "            target_len = len_buckets[i]\n",
    "            current_context = random.choice(contexts)\n",
    "            \n",
    "            # 사용자 제공 조건을 집약한 정교한 시스템 프롬프트 [cite: 44, 55]\n",
    "            system_prompt = f\"\"\"\n",
    "            당신은 한국어 대화 데이터 생성 전문가입니다. 다음 조건을 완벽히 만족하는 '일반 대화(04)'를 생성하세요.\n",
    "            \n",
    "            [지침]\n",
    "            - 주제: {current_context} (부정적인 표현이나 비속어 장난이 섞여도 됨)\n",
    "            - 성격: 자연스럽지만 부정적인 일상 대화. 단, 괴롭히는 뉘앙스(위계관계 압박 등)는 절대 없어야 함.\n",
    "            - 필수 활용 가능 단어: 죽이, 살리, 내놔, 뒤지, 새끼, 만원, 협박, 갈취, 부장님, 돼지, 환불, 경찰, 신고, 살려주세요, 돈이 등\n",
    "            - 길이: {target_len} 내외\n",
    "            - 발화 횟수: 4~8턴\n",
    "            - 형식: \"{i+1}. (약 {target_len}자)\"로 시작하고, 이후 화자 구분(A:, B:)을 포함한 대화문 출력\n",
    "            \"\"\"\n",
    "\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\", # 비용 효율성 및 속도 최적화 [cite: 30]\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": \"조건에 맞는 한국어 일상 대화 샘플을 하나 생성해줘.\"}\n",
    "                    ],\n",
    "                    temperature=0.9 # 다양성 확보를 위한 높은 창의성 설정 [cite: 41]\n",
    "                )\n",
    "                \n",
    "                conv_text = response.choices[0].message.content.strip()\n",
    "                generated_data.append({\n",
    "                    \"번호\": i + 1,\n",
    "                    \"class\": \"일반 대화\",\n",
    "                    \"conversation\": conv_text,\n",
    "                    \"설정길이\": target_len,\n",
    "                    \"상황분류\": current_context\n",
    "                })\n",
    "                \n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f\"✅ {i+1}/{total_count}개 생성 중...\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"API 오류 발생 (인덱스 {i}): {e}\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 사용자에 의해 중단되었습니다. 현재까지의 데이터를 저장합니다.\")\n",
    "\n",
    "    # 3. 데이터프레임 변환 및 엑셀 저장\n",
    "    if generated_data:\n",
    "        new_df = pd.DataFrame(generated_data)\n",
    "        \n",
    "        # 엑셀 파일로 저장 (xlsx 파일을 위해 openpyxl 라이브러리가 필요할 수 있습니다)\n",
    "        file_name = \"custom_normal_dialogue_300.xlsx\"\n",
    "        new_df.to_excel(file_name, index=False, engine='openpyxl')\n",
    "        \n",
    "        print(f\"\\n✨ 생성 완료! '{file_name}' 파일이 저장되었습니다.\")\n",
    "        print(new_df.head())\n",
    "    else:\n",
    "        print(\"생성된 데이터가 없습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_custom_normal_to_excel(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ce420dd-5001-4eac-b2d3-0b2b001f2f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨ 정제 성공! 'custom_normal_dialogue_300_cleaned.csv' 파일이 생성되었습니다.\n",
      "\n",
      "--- 첫 번째 데이터 확인 ---\n",
      "야, 너 내가 만원 빌린 거 언제 갚을 거야? 진짜 죽이기 전에 내놔.\n",
      "뭔 소리야? 내가 언제 네한테 만원 빌렸다고? 새끼야, 진짜.\n",
      "기억 안 나? 그날 너 자꾸 협박하더니 나한테 돈 갈취하려고 했잖아!\n",
      "어? 그거 그냥 농담이었어! 경찰 신고하고 싶으면 해봐, 내가 살아남을게.\n",
      "그러니까! 살려주세요, 내 돈이 문제야!\n",
      "내가 돈 없으면 환불도 못 받아. 정말 뒤지기 싫다면 알아서 해!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# [수정 포인트] 파일 이름을 확인하세요.\n",
    "FILE_NAME = 'custom_normal_dialogue_300.csv'\n",
    "\n",
    "def clean_conversation(text):\n",
    "    \"\"\"\n",
    "    1. 번호 및 글자 수 정보 제거 (예: 1. (약 150자))\n",
    "    2. 화자 식별자 제거 (A:, B: 등)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    # 1. 시작 번호와 (약 XXX자) 패턴 제거\n",
    "    text = re.sub(r'^\\d+\\.\\s*(\\(약?\\s*\\d+~\\d+자\\))?\\s*', '', text)\n",
    "    \n",
    "    # 2. 각 줄의 시작 부분에 있는 화자 이름(A:, 인물A: 등)과 콜론 제거\n",
    "    text = re.sub(r'^[^:\\n]+:\\s*', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # 3. 앞뒤 공백 제거 및 빈 줄 제외하고 다시 합치기\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "# 파일 읽기 및 정제 수행\n",
    "try:\n",
    "    if os.path.exists(FILE_NAME):\n",
    "        # [핵심 수정] encoding='cp949'를 추가하여 한글 인코딩 오류 해결\n",
    "        df = pd.read_csv(FILE_NAME, encoding='cp949')\n",
    "        \n",
    "        # 정제 함수 적용\n",
    "        df['conversation'] = df['conversation'].apply(clean_conversation)\n",
    "        \n",
    "        # 4단계: 최종 저장 (엑셀에서도 잘 열리도록 utf-8-sig 사용) [cite: 74]\n",
    "        output_name = \"custom_normal_dialogue_300_cleaned.csv\"\n",
    "        df.to_csv(output_name, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"✨ 정제 성공! '{output_name}' 파일이 생성되었습니다.\")\n",
    "        print(\"\\n--- 첫 번째 데이터 확인 ---\")\n",
    "        print(df['conversation'].iloc[0])\n",
    "    else:\n",
    "        print(f\"❌ 파일을 찾을 수 없습니다: {FILE_NAME}\")\n",
    "\n",
    "except UnicodeDecodeError:\n",
    "    # 혹시 CP949로도 안 될 경우 EUC-KR 시도\n",
    "    df = pd.read_csv(FILE_NAME, encoding='euc-kr')\n",
    "    print(\"💡 EUC-KR 인코딩으로 파일을 읽었습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498716c1-77c3-4f84-b328-f3bd8487f781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
